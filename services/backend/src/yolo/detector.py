import os
import cv2  # opencvå›¾åƒå¤„ç†åº“
import random  # ç”Ÿæˆéšæœºæ•°ï¼ˆç”¨äºéšæœºé€‰æ‹©é¢œè‰²ï¼‰
import torch  # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
from typing import List, Optional  # ç”¨äºç±»å‹æ³¨è§£
from ultralytics import YOLO  # Ultralytics YOLOæ¨¡å‹ å®˜æ–¹å®ç°åº“
from pathlib import Path
from dataclasses import dataclass


@dataclass  # ä½¿ç”¨dataclassç®€åŒ–ç±»çš„å®šä¹‰
class DetectorCOnfig:
    """æ£€æµ‹å™¨é…ç½®ç±»-é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®å‚æ•°
    ä½¿ç”¨@dataclassè£…é¥°å™¨çš„ä¼˜åŠ¿ï¼š
    1. è‡ªåŠ¨ç”Ÿæˆ__init__æ–¹æ³•
    2. è‡ªåŠ¨ç”Ÿæˆ__repr__æ–¹æ³•
    3. ç±»å‹å®‰å…¨
    4. ä»£ç æ›´ç®€æ´
    """

    default_conf_threshold: float = (
        0.25  # é»˜è®¤ç½®ä¿¡åº¦é˜ˆå€¼ï¼šè¶…è¿‡25%çš„æ£€æµ‹ç»“æœæ‰è¢«è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
    )
    default_imgsz: int = 640  # YOLOæ¨¡å‹çš„æ ‡å‡†è¾“å…¥å°ºå¯¸ï¼Œæ‰€æœ‰è¾“å…¥å›¾ç‰‡éƒ½ä¼šè¢«ç¼©æ”¾åˆ°640x640åƒç´ (ç²¾åº¦å’Œé€Ÿåº¦çš„å¹³è¡¡ç‚¹)
    output_image_dir: str = (
        "src/yolo/output/images"  # å›¾ç‰‡è¾“å‡ºç›®å½•ï¼šå¤„ç†åçš„å›¾ç‰‡ä¿å­˜ä½ç½®
    )
    output_video_dir: str = (
        "src/yolo/output/videos"  # è§†é¢‘è¾“å‡ºç›®å½•ï¼šå¤„ç†åçš„è§†é¢‘ä¿å­˜ä½ç½®
    )
    models_dir: str = "src/yolo/models"  # æ¨¡å‹ç›®å½•ï¼šå­˜æ”¾YOLOæ¨¡å‹æ–‡ä»¶çš„ä½ç½®


# è‡ªå®šä¹‰ä¸€ä¸ªDectorç±»ï¼Œç”¨äºç›®æ ‡æ£€æµ‹
class Detector:
    """
    YOLO ç›®æ ‡æ£€æµ‹å™¨ä¸»ç±»
    è¿™ä¸ªç±»å°±åƒä¸€ä¸ª"AIæ£€æµ‹ä¸“å®¶":
    1.åˆå§‹åŒ–æ—¶é€‰æ‹©å·¥ä½œè®¾å¤‡(CPU,GPU)
    2.åŠ è½½ä¸“ä¸šæŠ€èƒ½(YOLOæ¨¡å‹)
    3.æ¥æ”¶å·¥ä½œä»»åŠ¡
    4.è¾“å‡ºæ£€æµ‹æŠ¥å‘Š
    """

    def __init__(
        self,
        model_path: str = "src/yolo/models/yolo11n.pt",
        config: Optional[DetectorCOnfig] = None,
    ):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ŒåŠ è½½YOLOæ¨¡å‹ã€‚

        å‚æ•°:
        - model_path: YOLOæ¨¡å‹çš„è·¯å¾„ï¼Œé»˜è®¤ä¸º"src/yolo/models/yolo11n.pt"
                      nè¡¨ç¤ºnanoï¼Œæœ€å°æœ€å¿«çš„ç‰ˆæœ¬
          config:é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or DetectorCOnfig()  # å¦‚æœæ²¡æœ‰æä¾›é…ç½®å¯¹è±¡ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
        self.model_path = model_path  # ä¿å­˜æ¨¡å‹è·¯å¾„
        self.device = self._get_device()  # ç¡®å®šä½¿ç”¨GPUè¿˜æ˜¯CPU
        self.load_model()  # åŠ è½½æ¨¡å‹
        self.results = []  # å­˜å‚¨æ£€æµ‹ç»“æœ

    def _get_device(self) -> str:
        """
        ç¡®å®šä½¿ç”¨GPUè¿˜æ˜¯CPUè¿›è¡Œè®¡ç®—ã€‚

        è¿”å›:
        - "cuda" å¦‚æœæœ‰å¯ç”¨çš„GPUï¼Œå¦åˆ™è¿”å› "cpu"
        """
        return "cuda" if torch.cuda.is_available() else "cpu"

    def load_model(self):
        """
        ä»ç±»æ„é€ å‡½æ•°å®šä¹‰çš„æ¨¡å‹è·¯å¾„ä¸­åŠ è½½YOLOæ¨¡å‹
        Return:
           è®¾ç½®self.modelä¸ºYOLOæ¨¡å‹
        """
        if not os.path.exists(self.model_path):  # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
            raise FileNotFoundError(f"Model file not found at {self.model_path}")

        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
        # ä½¿ç”¨YOLOç±»åŠ è½½æ¨¡å‹æ–‡ä»¶
        self.model = YOLO(model=self.model_path)
        # ä¸Šä¸€è¡Œä»£ç åšäº†å¾ˆå¤šå·¥ä½œï¼š
        # 1.è¯»å–.ptæ–‡ä»¶ï¼ˆPytorchæ¨¡å‹æ–‡ä»¶ï¼‰
        # 2.è§£ææ¨¡å‹ç»“æ„å’Œæƒé‡
        # 3.åˆå§‹åŒ–ç¥ç»ç½‘ç»œ
        # 4.åŠ è½½è®­ç»ƒå¥½çš„å‚æ•°
        # 5.å‡†å¤‡æ¨¡å‹ç”¨äºæ¨ç†
        self.model_name = Path(
            self.model_path
        ).stem  # æå–æ¨¡å‹åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰ stem()æ˜¯æå–å•ä¸ªæ–‡ä»¶çš„åç§°
        print(f"æ¨¡å‹åç§°: {self.model_name}åŠ è½½æˆåŠŸï¼")

    def detect_picture(
        self,
        image_path: List[str],
        conf_threshold: float = None,
        output_dir: str = "src/yolo/output/images",
    ):
        """
        å¯¹è¾“å…¥å›¾åƒè¿›è¡Œç›®æ ‡æ£€æµ‹ - æ”¯æŒè¿›åº¦å›è°ƒ

        å‚æ•°:
        - image_path: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        - conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤ä¸º0.25
        - output_dir: æ£€æµ‹ç»“æœå›¾åƒçš„è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º'src/yolo/output/images'

        è¿”å›:
        - output_dir: ä¿å­˜æ£€æµ‹ç»“æœå›¾åƒçš„ç›®å½•è·¯å¾„
        """

        # æ”¯æŒè¿›åº¦å›è°ƒ å®šä¹‰å†…éƒ¨è¿›åº¦æŠ¥å‘Šå‡½æ•° å¾…å®Œæˆ

        # å‚æ•°å¤„ç†ï¼šå¦‚æœæ²¡æœ‰æŒ‡å®šé˜ˆå€¼ï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
        conf_threshold = conf_threshold or self.config.default_conf_threshold

        # å‚æ•°å¤„ç†ï¼šå¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
        output_dir = output_dir or self.config.output_image_dir

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        self.results = self.model.predict(
            source=image_path,  # è¾“å…¥å›¾åƒè·¯å¾„
            conf=conf_threshold,  # ç½®ä¿¡åº¦é˜ˆå€¼
            save=False,  # ä¿å­˜æ£€æµ‹ç»“æœå›¾åƒ
            device=self.device,  # ä½¿ç”¨çš„è®¾å¤‡
            show=False,  # ä¸æ˜¾ç¤ºæ£€æµ‹çª—å£
            imgsz=self.config.default_imgsz,  # å°†å›¾ç‰‡ç¼©æ”¾åˆ°640x640
        )

        print("æ£€æµ‹å®Œæˆï¼Œæ­£åœ¨ä¿å­˜ç»“æœ...")
        self.save_picture_result(output_dir)  # ä¿å­˜æ£€æµ‹ç»“æœå›¾åƒ
        print(f"ç»“æœå·²ä¿å­˜åˆ°:{output_dir}")
        return output_dir

    def detect_video(
        self, video_path: str, conf_threshold: float = None, output_dir: str = None
    ):
        """
        é€å¸§å¤„ç†è§†é¢‘ç›®æ ‡æ£€æµ‹
        1.æ‰“å¼€è§†é¢‘æ–‡ä»¶
        2.é€å¸§è¯»å–è§†é¢‘å†…å®¹
        3.å¯¹æ¯ä¸€å¸§è¿›è¡Œç‰©ä½“æ£€æµ‹
        4.åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ

        å‚æ•°:
        - video_path(str): è§†é¢‘æ–‡ä»¶è·¯å¾„
        - conf_threshold(float): ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤ä¸ºDetectorConfigé‡Œé¢çš„0.25
        - output_dir(str): è¾“å‡ºè§†é¢‘æ–‡ä»¶çš„ç›®å½•ï¼Œé»˜è®¤ä¸ºDetectorConfigé‡Œé¢çš„'src/yolo/output/videos'
        è¿”å›:
        - output_video_path(str): ä¿å­˜æ£€æµ‹ç»“æœè§†é¢‘çš„å®Œæ•´è·¯å¾„
        """
        # å‚æ•°å¤„ç†ï¼šä½¿ç”¨é…ç½®é»˜è®¤å€¼
        conf_threshold = conf_threshold or self.config.default_conf_threshold
        output_dir = output_dir or self.config.output_video_dir

        print(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
        print(f"ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"åˆ›å»ºè¾“å‡ºç›®å½•:{output_dir}")

        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)

        # æ£€æŸ¥è§†é¢‘æ˜¯å¦æˆåŠŸæ‰“å¼€
        if not cap.isOpened():
            error_msg = f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶:{video_path}"
            print(error_msg)
            return ValueError(error_msg)

        # è·å–è§†é¢‘å±æ€§ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))  # å¸§ç‡(æ¯ç§’å¸§æ•°) æ¯ç§’æ’­æ”¾å¤šå°‘å¸§
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # è§†é¢‘å®½åº¦(px)
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # è§†é¢‘é«˜åº¦(px)

        print(f"è§†é¢‘ä¿¡æ¯: {width}x{height} @ {fps}FPS")

        # è®¾ç½®è§†é¢‘ç¼–ç æ ¼å¼
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")  # ä½¿ç”¨mp4ç¼–ç  å…¼å®¹æ€§è¾ƒå¥½

        # ç”Ÿæˆè¾“å‡ºè§†é¢‘æ–‡ä»¶å
        video_name = Path(video_path).stem
        output_video_path = os.path.join(
            output_dir, f"{video_name}_{self.model_name}_detected.mp4"
        )
        print(f"è¾“å‡ºè§†é¢‘è·¯å¾„:{output_video_path}")

        # åˆ›å»ºè§†é¢‘å†™å…¥å¯¹è±¡
        out = cv2.VideoWriter(output_video_path, fourcc, fps, {width, height})

        # æ£€æŸ¥è§†é¢‘å†™å…¥å¯¹è±¡æ˜¯å¦åˆ›å»ºæˆåŠŸ
        if not out.isOpened():
            raise RuntimeError(f"æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘æ–‡ä»¶:{output_video_path}")

        # é¢œè‰²å­—å…¸ï¼šä¸ºä¸åŒç±»åˆ«çš„ç‰©ä½“åˆ†é…ä¸åŒé¢œè‰²
        colors = {}

        frame_count = 0  # å¸§è®¡æ•°å™¨ï¼Œåœ¨å¤„ç†è¿‡ç¨‹ä¸­ç»Ÿè®¡å¤„ç†äº†å¤šå°‘å¸§

        # å¼€å§‹é€å¸§å¤„ç†è§†é¢‘
        print("å¼€å§‹é€å¸§å¤„ç†..")
        while cap.isOpened():
            # è¯»å–ä¸‹ä¸€å¸§
            ret, frame = cap.read()

            # æ£€æŸ¥æ˜¯å¦æˆåŠŸè¯»å–å¸§
            if not ret:
                print("è§†é¢‘å¤„ç†å®Œæˆ")
                break

            frame_count += 1  #

            # æ¯å¤„ç†100å¸§æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if frame_count % 100 == 0:
                print(f"å·²å¤„ç†{frame_count}å¸§...")

            results = self.model.predict(
                frame,
                device=self.device,
                conf=conf_threshold,
                imgsz=self.config.default_imgsz,
            )

            for result in results:  # é’ˆå¯¹æ‰€æœ‰å¤„ç†å¸§é‡Œé¢çš„æ¯ä¸€å¸§
                if result.boxes is not None:  # æ·»åŠ å®‰å…¨æ£€æŸ¥
                    for box in result.boxes:  # é’ˆå¯¹æ¯ä¸€å¸§é‡Œé¢çš„æ¯ä¸€ä¸ªæ£€æµ‹æ¡†
                        x1, y1, x2, y2 = map(
                            int, box.xyxy[0]
                        )  # æå–è¾¹ç•Œæ¡†åæ ‡å¹¶è½¬æ¢ä¸ºæ•´æ•°
                        conf = box.conf[0].item()  # ä»boxçš„confå±æ€§ä¸­æå–ç½®ä¿¡åº¦
                        class_id = int(
                            box.cls[0].item()
                        )  # ä»boxçš„clså±æ€§ä¸­æå–ç±»åˆ«IDå¹¶è½¬æ¢ä¸ºæ•´æ•°
                        class_name = result.names[
                            class_id
                        ]  # ä»resultçš„nameså±æ€§ä¸­æå–ç±»åˆ«åç§°

                        if conf >= conf_threshold:  # åªå¤„ç†ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼çš„æ£€æµ‹ç»“æœ
                            # ä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…éšæœºé¢œè‰²
                            if class_id not in colors:
                                colors[class_id] = (
                                    random.randint(0, 255),
                                    random.randint(0, 255),
                                    random.randint(0, 255),
                                )  # ç”Ÿæˆéšæœºé¢œè‰²

                            color = colors[class_id]
                            label = f"{class_name} {conf:.2f}"  # æ ‡ç­¾æ–‡æœ¬ åŒ…å«ç±»åˆ«åç§°å’Œç½®ä¿¡åº¦
                            # åœ¨å¸§ä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
                            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                            cv2.putText(
                                frame,
                                label,
                                (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX,
                                0.5,
                                color,
                                2,
                            )

            # å°†å¤„ç†åçš„å¸§å†™å…¥è¾“å‡ºè§†é¢‘
            out.write(frame)

        cap.release()  # é‡Šæ”¾è§†é¢‘æ•è·å¯¹è±¡
        out.release()  # é‡Šæ”¾è§†é¢‘å†™å…¥å¯¹è±¡

        print(f"è§†é¢‘å¤„ç†å®Œæˆï¼Œå…±å¤„ç†{frame_count}å¸§")
        return output_video_path

    def change_model(self, new_model_path: str):
        """
        åˆ‡æ¢ä¸€ä¸ªæ–°çš„YOLOæ¨¡å‹
        Args:
            new_model_path (str): æ–°æ¨¡å‹çš„è·¯å¾„
        """
        pre_path = self.config.models_dir
        full_path = pre_path + new_model_path
        if not os.path.exists(full_path):
            raise FileNotFoundError(f"Model file not found at {full_path}")

        self.model_path = full_path
        self.load_model()

    def save_picture_result(self, output_dir: str = "src/core/yolo/output/images"):
        """
        ä¿å­˜æ£€æµ‹ç»“æœä¸ºå›¾ç‰‡
        Args:
            output_dir (str): è¾“å‡ºç›®å½•
        """
        for i, r in enumerate(
            self.results
        ):  # éå†æ‰€æœ‰æ£€æµ‹ç»“æœ è¿”å›ç¬¬ä¸€ä¸ªå€¼æ˜¯ç´¢å¼•ï¼Œç¬¬äºŒä¸ªå€¼æ˜¯çœŸæ­£çš„æ¯ä¸ªç»“æœ
            img_with_boxes = r.plot(labels=True, line_width=2)  # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†
            cv2.imwrite(output_dir + f"/detected_{i}.jpg", img_with_boxes)  # ä¿å­˜å›¾åƒ


# ç®€å•æµ‹è¯•ä»£ç ï¼Œæµ‹è¯•å›¾åƒå¯ä»¥ä¼ å…¥yolo/test_imageæ–‡ä»¶å¤¹é‡Œ
if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•YOLOæ£€æµ‹å™¨...")

    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
    model_path = "src/yolo/models/yolo11n.pt"
    test_image_dir = "src/yolo/test_image"

    try:
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œæµ‹è¯•æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path) or not os.path.exists("src/yolo/test_image"):
            raise FileNotFoundError(
                f"æ¨¡å‹æˆ–æµ‹è¯•æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {model_path} æˆ– src/yolo/test_images"
            )

        # è·å–æµ‹è¯•å›¾ç‰‡åˆ—è¡¨
        image_extensions = [".jpg", ".jpeg", ".png", "bmp"]
        test_images = []

        # éå†æµ‹è¯•æ–‡ä»¶å¤¹ï¼Œæ”¶é›†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        for file in os.listdir(test_image_dir):  # è¿™é‡Œçš„fileæ˜¯å­æ–‡ä»¶å
            if any(file.lower().endswith(ext) for ext in image_extensions):
                test_images.append(
                    os.path.join(test_image_dir, file)
                )  # æŠŠæµ‹è¯•å›¾ç‰‡çš„è·¯å¾„æ‹¼æˆå®Œæ•´è·¯å¾„

        if not test_images:
            print(f"é”™è¯¯ï¼šåœ¨ {test_image_dir} ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(image_extensions)}")
            exit(1)

        print(f"æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡:")
        for img in test_images:
            print(f"  - {img}")

        # åˆ›å»ºæ£€æµ‹å™¨
        print(f"\næ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
        detector = Detector(model_path)
        print(f"âœ… æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨è®¾å¤‡: {detector.device}")

        # æ‰§è¡Œå›¾ç‰‡æ£€æµ‹
        print(f"\nğŸ” å¼€å§‹æ£€æµ‹ {len(test_images)} å¼ å›¾ç‰‡...")
        output_dir = detector.detect_picture(test_images, conf_threshold=0.25)
        print(f"âœ… å›¾ç‰‡æ£€æµ‹å®Œæˆï¼Œç»“æœä¿å­˜è‡³: {output_dir}")

        # æ˜¾ç¤ºç»“æœç»Ÿè®¡
        if os.path.exists(output_dir):
            result_files = [f for f in os.listdir(output_dir) if f.endswith(".jpg")]
            print(f"ğŸ“Š ç”Ÿæˆäº† {len(result_files)} ä¸ªç»“æœæ–‡ä»¶:")
            for result_file in result_files:
                print(f"  - {os.path.join(output_dir, result_file)}")

        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
